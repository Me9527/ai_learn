# 什么是大模型
+ 大模型指的是大型语言模型（Large Language Model, LLM），它是人工智能领域的一种深度学习模型，是一个旨在理解、生成和响应人类文本语言的神经网络。（类似人脑，学习和使用知识的方式)。
+ 大模型是在海量文本数据上训练得到的模型，基本涵盖了互联网上所有公开可用的文本数据集。训练一次需要价值10亿的GPU集群，加上数月的时间。

## 大模型与人类大脑对比
+ 从简单到复杂： 人类在学习过程中，也是从简单的概念和规则开始，逐渐掌握更复杂、更抽象的知识和技能。例如，婴儿从模仿发音到理解语法，再到能进行复杂的对话和推理。这与大模型从海量数据中学习基础语言模式，进而展现出高级能力有异曲同工之妙。
+ 模式识别与泛化： 大模型和人脑都擅长从大量经验中识别模式，并将这些模式泛化应用到新的、未见过的情境中。人脑通过经验形成概念和世界模型，大模型通过参数学习并编码"世界知识"。
+ 知识累积： 人脑通过学习、阅读、交流不断积累知识，而大模型通过训练数据"吸收"了大量文本中蕴含的知识。

## 大模型特点（知道的真多）
+ "世界知识"的掌握： 在海量数据上训练使得大模型"吸收"了大量的世界知识，使其能够回答各种百科知识问题，并进行一定的知识推理。已经完成了对全世界所有公开的文字类知识的学习，比博士还博士。
+ 多模态能力 (Multimodality)： 现代大模型不仅限于文本，还能够理解和生成图像、音频、视频等多种模态的信息，实现跨模态的交互和生成。例如，能看图说话，或根据文本描述生成图片。 
+ 通用性 (Generalization)： 一个经过大规模预训练的大模型可以应用于多种不同的下游任务，而无需针对每个任务进行从头训练。它相当于一个"基础模型"或"基座模型"，可以作为各种AI应用的基础（在此之上进行，微调+RAG）。   
+ 涌现能力 (Emergent Abilities)： 这是大模型最令人惊喜的特性之一。大模型的涌现能力是计算规模累积到一定程度后，量变引起质变的体现，展现了强大的模式识别、关联和生成能力。它在某些方面能与人类的认知能力相媲美，甚至超越人类。
    
    + 涌现能力的作用：
        + 处理更复杂的任务： 从简单的信息提取到多步推理、问题解决、创意生成。
        + 实现更高级的自动化： 例如，自动生成复杂报告、进行数据分析、辅助科学研究。
        + 提供更智能的用户体验： 聊天机器人变得更像真人，能够理解更深层次的意图和上下文。
        + 推动通用人工智能（AGI）的发展： 涌现能力被视为模型迈向更通用智能的重要标志，因为它们展现出类似人类的泛化和适应能力。
        + 作为基础模型（Foundation Model）： 拥有涌现能力的大模型可以作为许多特定AI应用的基础，减少从头开发的成本和时间。
    + 涌现能力的例子：
        + 上下文学习（In-context Learning）： 给予模型几个示例，它就能在不进行额外训练的情况下，学会完成类似的任务。例如，请分析一下今天股市的版块指数，并按如下JSON格式******输出（你指定的数据格式）。
        + 逐步推理（Step-by-step Reasoning/Chain-of-Thought）： 当提示模型"一步一步地思考"时，它能够将复杂的问题分解为多个中间步骤，然后逐步解决，最终得到正确的答案。这在数学问题、逻辑推理和复杂编程任务中尤为明显。
        + 指令遵循（Instruction Following）： 模型能够理解和执行非常复杂、多约束、多条件的指令，即使这些指令在训练数据中从未以完全相同的形式出现过。
        + 代码生成与理解： 生成高质量的代码，甚至根据需求描述文字生成完整的程序。
        + 世界知识与常识： 展现出对广泛世界知识和日常常识的理解，并能用于推理。


# 主流大模型
<table>
<thead>
  <tr>
    <th width='80px;'>特性</th>
    <th width='120px;'>GPT (OpenAI)</th>
    <th width='120px;'>Gemini (Google)</th>
    <th width='140px;'>Claude (Anthropic)</th>
    <th width='140px;'>DeepSeek (深度求索)</th>
    <th width='120px;'>Llama (Meta AI)</th>
    <th width='120px;'>Qwen (阿里)</th>
    <th width='140px;'>Doubao (字节跳动)</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><strong>自然语言理解与生成</strong></td>
    <td>自然，流畅、连贯、创造力强，业界领先。</td>
    <td>尤其擅长长文本和复杂语境，创意写作能力突出。</td>
    <td>长文本理解、复杂指令遵循，注重连贯性和深度。</td>
    <td>中文表现优秀，逻辑推理有特点，代码编写，数学问题求解方面看齐国际第一梯队。</td>
    <td>强大，接近顶尖闭源模型，多样性和可定制性强。</td>
    <td>中文突出，多语言良好，代码生成、创意写作出色。</td>
    <td>中文出色，基于海量中文数据，抖音内部用的多。</td>
  </tr>
  <tr>
    <td><strong>通用能力</strong></td>
    <td>优秀，综合最强，各项任务均顶尖，引领通用AI。</td>
    <td>优秀，多模态多功能，跨模态信息整合强，代码、数学出色。</td>
    <td>优秀，注重安全、伦理、指令遵循，长文本问答、代码辅助编程开发。</td>
    <td>优秀，国产第一梯队，代码编写、数学、推理等专业领域领先。</td>
    <td>优良，接近闭源模型的能力，开源社区微调潜力大。</td>
    <td>优良，中文领先，代码、数学、推理、多语言支持均衡。</td>
    <td>良，中文通用能力强，广泛应用于抖音内部业务，落地能力强。</td>
  </tr>
  <tr>
    <td><strong>复杂推理</strong></td>
    <td>优秀，多步骤、逻辑演绎、问题解决、复杂编程。</td>
    <td>优秀，与GPT相当，原生多模态融合优势。</td>
    <td>强大，擅长遵循复杂规则，逻辑链构建严谨。</td>
    <td>强大，特别是代码和数学推理，专业领域解决能力强。</td>
    <td>目前有进步，多步推理和逻辑分析能力增强。</td>
    <td>出色，特别是代码和数学推理，中文基准测试表现亮眼。</td>
    <td>中文语境下较强，能处理长文本多轮对话逻辑。</td>
  </tr>
  <tr>
    <td><strong>多模态</strong></td>
    <td>优秀，文本、图像、语音输入输出，端到端交互。</td>
    <td>优秀，原生多模态，文本、图像、音频、视频理解与生成。</td>
    <td>优良视觉能力，图像理解、分析和多模态推理。</td>
    <td>积极发展中，部分版本支持文生图，未来潜力大。</td>
    <td>目前不支持，社区探索添加多模态能力。</td>
    <td>支持多模态音频、视频、国内领先</td>
    <td>豆包家族具备多模态能力，文生图、语音识别/合成等。</td>
  </tr>
  <tr>
    <td><strong>上下文窗口大小</strong></td>
    <td>128K tokens (GPT-4o)，约12万汉字</td>
    <td>1M tokens (Gemini 1.5 Pro)，约120万汉字</td>
    <td>200K tokens (Claude 3 Opus)，约20万汉字</td>
    <td>32K tokens (DeepSeek-V2)，约3万汉字</td>
    <td>8K tokens (Llama 3默认，可扩展)，约8000个汉字</td>
    <td>128K tokens (Qwen2系列)，约12万汉字</td>
    <td>部分版本支持128K tokens (持续优化中)</td>
  </tr>
  <tr>
    <td><strong>性价比</strong></td>
    <td>优秀，高性能，成本优化好，速度快。</td>
    <td>优秀，高性能，大上下文处理高效。</td>
    <td>优秀，高性能，效率与性能权衡（Haiku、Sonnet、Opus）。</td>
    <td>优秀，创新架构，显著降低推理成本，提升效率，对比国外模型，价格极具优势。</td>
    <td>开源模型，可以按需调整，技术团队的能力决定性价比</td>
    <td>优良，中文任务高效，速度快，输出质量高。</td>
    <td>成本有优势，价格低廉。</td>
  </tr>
  <tr>
    <td><strong>安全性与道德伦理</strong></td>
    <td>最大限度减少有害输出。</td>
    <td>强调安全性和偏见避免。</td>
    <td>核心理念，设计之初注重安全性、避免偏见和有害信息。</td>
    <td>积极探索，遵循法规，构建安全负责任AI。</td>
    <td>作为开源模型，其最终的安全性和伦理责任更多取决于使用者和社区的微调</td>
    <td>大量投入，遵循法规，提供负责任AI服务。</td>
    <td>强调内容安全合规，内部业务持续打磨。</td>
  </tr>
  <tr>
    <td><strong>是否开源</strong></td>
    <td>否</td>
    <td>否</td>
    <td>否</td>
    <td>是</td>
    <td>是</td>
    <td>是（或部分是)</td>
    <td>是（或部分是)</td>
  </tr>
</tbody>
</table>



+ 上下文窗口大小: 1个token并不等于一个汉字，或一个英文单词，且不同模型的分词器也不同，所以这里只是大概的参考值。大模型基本都按token用量收费。
+ 性价比:这是一个不好衡量的指标，因为网上都是用固定场景做测试的；如果针对不同的具体业务功能，不同模型下的效果是有差别的，还会涉及的提示词工程，微调，RAG的影响。这里只给出一个主观的参考。
+ 安全性与道德伦理:这也是一个不好细评的指标，因为不同的种族，国家，对很多事情的理解是不一样的。模型的回答是否带有政治偏向、是否遵循当地法律、是否有悖道德伦理。

### 通用能力： 
+ 通用能力包括在文本生成、常识逻辑推理、数学能力、多语言理解、多模态识别、代码生成等。基础模型在不需要微调和RAG的情况下，通用能力的好坏，直接体现在模型好不好用，是不是能像人类一样理解和思考问题。

### 上下文窗口：
+ 大语言模型的"上下文窗口"（Context Window）是指模型在生成响应时能够"记住"或同时处理的信息量。您可以将其理解为模型的工作记忆或阅读容量。如果输入的信息量超过了模型的上下文窗口限制，模型可能无法完全理解所有内容，导致回复不完整或遗漏细节 。
+ 大模型上下文窗口的显著增加，直接促成了更复杂的应用，如全面的文档分析、长篇内容生成以及对大量数据的多步骤推理。这种能力提升，减少了对复杂分块和检索增强生成（RAG）策略的需求，从而简化了开发过程，并提高了用户体验中的连贯性。
+ 超长的上下文让模型能够处理"整个代码库"或"10本以上1000页大小的书籍"；现在最先进的大模型能够处理企业级文档、法律文本、科学论文和大型代码库。
    + 示例：
      + 用户问："天气如何？" → 模型答："北京晴，25℃" → 用户再问："需要带伞吗？" → 模型结合上下文判断，答：无需带伞。
      + 如果上下文很短， 用户再问："需要带伞吗？大模型就不记得之前回答的"北京晴，25℃"了，就会产生一个不确切的回答。

    + DeepSeek-R1的32K模型支持约3.2万汉字。最新版的DeepSeek支持128k上下文。
    + 如GPT-4的32K版本处理约2.5万汉字。
    + 一般大模型的上下文大小是8k-32K

### 多模态：
+ 大模型在多模态能力（包括文本、图像、音频和视频）方面的快速发展，预示着人工智能与世界交互方式的根本性转变。这不仅仅是处理不同数据类型的问题，更是为了实现更直观、自然和全面的人机交互界面，为更复杂的具身智能和现实世界自动化铺平道路。
+ 目前的使用多模态交互 跟使用自然语言与大模型交互比还是有不小差距的。未来可期。

# 什么是AI Agent
+ 人工智能代理（AI Agent）是一个能够感知环境、自主决策、执行行动，并在此过程中学习和适应的智能实体。它不是一个单一的AI模型，是一个拥有特定目标、能够利用工具、并与环境进行持续交互的系统。
## AI Agent与大模型的关系：
+ AI Agent就是给大语言模型LLM这个大脑装上了手和脚，这样AI Agent就能够根据人的要求，自主完成相应工作。
+ 大模型技术做为核心，为AI Agent提供了强大的语言理解、推理、规划和生成能力，而AI Agent则是将LLM的语言理解、推理和生成能力转化为实际行动的系统。
+ AI Agent可调用多个大模型，综合不同大模型的特性来完成某个具体功能场景。

## AI Agent 的核心要素：
+ 感知 (Perception)： 能够从环境中获取信息（例如，接收用户指令、读取文档、分析图像、访问网页数据等）。
+ 规划/决策 (Planning/Decision-making)： 基于感知到的信息和预设目标，进行内部思考、分析和规划，决定下一步的行动。这通常涉及到大模型的推理能力，将大目标分解为更小的、可执行的子任务。
+ 行动 (Action)： 执行决策，与环境进行交互（例如，调用API、写入文件、发送邮件、执行代码、与用户对话等）。
+ 泛化能力： 能够学习并泛化到新的、未见过的类似任务。
+ 记忆/学习 (Memory/Learning)： 能够记住过去的经验、对话或操作，并从中学习，以优化未来的决策和行动，实现持续的自我改进。

## AI Agent能做什么：
+ AI Agent的能力远超简单的问答，它能够执行一系列复杂的、多步骤的任务。
+ 自动化工作流： 自动完成重复性、规则性的任务，例如数据收集、报告生成、邮件发送、日程管理等。
+ 复杂问题解决： 拆解复杂问题，逐步思考并利用工具解决问题，例如软件开发、研究分析、产品设计等。
+ 信息检索与整合： 从多个信息源（网络、数据库、文档）检索信息，并进行理解、筛选、整合，提供有条理的答案或报告。
+ 个性化服务： 根据用户的需求、偏好和上下文，提供高度定制化的推荐、建议或服务。
+ 跨工具协作： 能够识别任务需要使用哪些工具，并自主调用这些工具（如搜索引擎、计算器、编程环境、外部API等）来完成任务。
+ 自主学习与优化： 通过与环境的持续交互，学习新的模式、改进决策策略，甚至学习使用新的工具。
+ 创意与内容生成： 不仅是文本生成，还能结合工具进行图像、视频、代码等的生成和优化。

## AI Agent相关的协议：
+ MCP：是一个开放、标准化的协议，旨在解决大模型与企业数据、工具和系统之间的"上下文"问题。它提供了一种通用方式，让AI Agent能够安全、可控地访问各种外部资源，从而让 LLM 获得更准确、更实时的信息，避免"幻觉"。
+ Function Calling：是大模型与外部工具或 API 进行交互的一种通信机制。
+ A2A：是Agent与Agent之间进行通信的协议。这是构建更复杂、更强大的多智能体系统的核心。
  + 相互关系：
    + Function Calling 是最基础的机制，它让大模型能够"知道"并"请求"执行外部操作。
    + MCP 在 Function Calling 的基础上更进一步，提供了一个标准化的框架来管理这些外部工具和数据源，特别关注企业级应用中的安全、控制和上下文管理。
    + 你可以将 Function Calling 理解为 LLM 的"意图识别"和"指令生成"，而 MCP 则是这些指令的"标准化执行层"。
    + A2A 则处于更高的抽象层次，它不关注单个 Agent 如何与工具交互（这些是 Function Calling 或 MCP 关注的），而是关注多个独立 Agent 如何相互交流、共享任务和协作完成复杂目标。

## AI Agent 例子：
+ Manus‌：是由中国团队 ‌Monica.im‌ 开发的 ‌全球首个通用型 AI Agent
  + https://manus.im/guest
+ Cursor：ai编程助手。打破原有编程模式。
  + https://www.cursor.com/cn
+ browser-use: AI浏览器，浏览器操作自动化。
  + https://github.com/browser-use/browser-use
+ 其他：https://otter.ai/   会议转录和总结；OpenAI 的 Operator

# 使用AI的方式
## 指令式
+ 指令式交互：一次性描述完你问题与期待的结果，然后调用大模型等待回复。适用于简单明确的问题。与大模型交互一次就能完成，不需要进行多轮交互。
  + 例如：
    + 请介绍一下什么是大模型。
    + 请用java写一个冒泡排序。
## 协作式
+ 对于复杂的问题很难通过一次交互就能得到期望的答案，需要与大模型进行多轮交互，才能得到比较满意的答案。类似人与人之间对复杂问题处理，都是由浅入深，通过多次反复沟通交流，最后达成一致的共识。
+ 用大模型解决复杂问题是一种协作式的问题解决过程。你扮演着引导者、背景提供者和批判性评估者的角色，而大模型则是一个强大的分析和生成引擎。通过清晰的定义、结构化的提示、迭代的沟通、角色扮演和思维链等技巧，你可以最大限度地发挥大模型的潜力，从而获得真正合理和有价值的解决方案。
  + 明确问题定义与目标：在与大模型沟通复杂问题之前，最重要的一步是你自己要对问题有清晰的理解。
  + 结构化你的提示：复杂问题往往需要分层、分步骤地引导大模型。
  + 角色扮演：让大模型扮演一个特定的角色，这会促使它从该角色的视角思考和回答问题。
  + 思维链：引导大模型逐步思考，展示其推理过程，而不是直接给出答案。这对于复杂问题尤为重要，可以帮助你发现大模型的推理漏洞，并进行纠正。
  + 迭代与精炼：与大模型的沟通很少是"一发入魂"的，特别是对于复杂问题，需要多次迭代与逐步精炼。

# 提示词，微调，RAG
在人工智能和大型语言模型 (LLM) 领域，提示词 (Prompting)，微调 (Fine-tuning) 和检索增强生成 (Retrieval Augmented Generation, RAG) 是三种关键技术，它们各自在与这些模型交互和优化其性能方面发挥着重要作用。理解它们之间的区别和联系对于有效利用大语言模型至关重要。


### 1. 提示词 (Prompting)

**定义：**
提示词（Prompt）是指用户提供给AI模型的输入，通常是自然语言文本。它可以是一个问题、一个指令、一段描述，甚至包含示例。通过精心设计的提示词，用户可以引导AI模型生成特定类型的输出，例如文本、代码、图像等。

**工作原理：**
大语言模型是基于其在大量文本数据上训练所学到的模式来预测下一个词（或token）。提示词为模型提供了上下文和任务方向。模型会根据这个输入来理解用户的意图，并生成它认为最相关的后续内容。

**特点：**
* **易用性高：** 不需要专业的编程或机器学习知识，任何人都可以通过自然语言与模型交互。
* **灵活性强：** 可以通过改变提示词的措辞、结构和包含的信息来探索模型不同的能力和输出风格。
* **即时生效：** 提示词的效果是即时的，用户可以快速迭代和调整以获得满意的结果。
* **无需模型修改：** 提示词是在不改变模型本身参数的情况下与模型交互的方式。

**提示工程 (Prompt Engineering):**
这是一门研究如何设计和优化提示词以使AI模型更有效、更准确地执行任务的学科。好的提示词能够清晰地传达意图、提供必要的上下文、指定输出格式等，从而显著提高生成结果的质量和相关性。

**示例：**
* 简单问题："法国的首都是哪里？"
* 指令："写一封关于产品发布的营销邮件，目标客户是小型企业主。"
* 带有上下文和角色的提示："假设你是一位资深的旅行规划师，请为我规划一个为期3天的辽宁沈阳家庭旅行行程，重点是文化体验和美食。"

### 特别说明
+ 提示词分系统提示词 (system prompt) 和 提示词 (user prompt) 两种
  + 提示词(user prompt)：通常指的是用户直接输入给模型的指令或问题。它定义了用户想要模型完成的具体任务或获取的信息。
  + 系统提示词(system prompt)：是在用户输入之前，由开发者或应用程序定义并提供给模型的一段"幕后"指令。它的主要目的是设定模型的整体行为、角色、语气、安全边界或输出格式等，从而影响模型对后续所有用户提示词的响应方式。系统提示词通常对用户是不可见的。
+ 区别与联系

| 特征         | 提示词 (Prompt)                      | 系统提示词 (System Prompt)                     |
| :----------- | :--------------------------------------- | :--------------------------------------------- |
| **提出者** | 用户                                     | 开发者/应用程序                                 |
| **可见性** | 对用户可见，用户直接输入                   | 通常对用户不可见或不可直接修改                     |
| **作用范围** | 影响当前这一次的对话交互响应               | 影响模型在整个会话中的行为、角色和输出的整体框架     |
| **修改频率** | 每次交互都可能更改或调整                   | 通常在会话开始时设置一次，或由开发者调整           |
| **目的** | 指导模型完成特定任务或回答特定问题           | 定义模型的"性格"、行为模式和安全限制             |

+ 用户与模型完成一次对话通常会包含三种消息User Message, Assistant Message, System Message。
  + 用户消息（User Message），就是用户要问的问题的自然语言描述，也可以叫提示词 (user prompt)。例如：你问，中国邮政成立于什么时候。
  + 模型回复消息（Assistant Message），就是大模型根据你的提问回复的结果。例如：模型回答：中国邮政成立于1896年。
  + 系统消息（System Message），其实就是系统提示词(System Prompt)，用来指导模型行为、设定角色、提供高级上下文的。这个通常不能由用户自己输入，是用户所使用的系统（应用程序）自带的。系统消息可以为空，系统提示词可以为空。
+ Function Message 这是Function calling使用的消息，这是大模型与外界交互用的消息，普通用户用不到。


### 2. 微调 (Fine-tuning)

**定义：**
微调是一种迁移学习技术，它采用一个已经在大型通用数据集上预训练好的模型（称为基础模型），并在一个更小、更特定于某个任务或领域的数据集上对其进行额外的训练。

**工作原理：**
预训练模型已经学习到了通用的语言理解和生成能力。微调通过在特定数据集上继续训练，调整模型的权重（参数），使其更好地适应特定任务的细微差别、术语、风格或知识。

**特点：**
* **提升特定任务性能：** 微调可以显著提高模型在特定领域的准确性和相关性，使其表现优于通用的基础模型。
* **知识内化：** 微调将特定领域的知识和模式更深层次地融入到模型参数中。
* **需要数据和计算资源：** 微调通常需要一定量的标注数据和相应的计算资源（如GPU）来进行训练。
* **模型参数改变：** 与提示词不同，微调会直接修改模型的内部参数。
* **静态知识：** 微调后的模型知识仍然是基于其训练数据的快照，如果领域知识更新迅速，模型可能需要重新微调。

**用例：**
* 训练一个聊天机器人，使其能够以特定品牌的语气和风格进行交流。
* 使模型能够理解和生成特定行业的术语和报告（例如，法律、医疗）。
* 提高模型在特定类型文本分类或情感分析任务上的准确率。

### 3. 检索增强生成 (Retrieval Augmented Generation, RAG)

**定义：**
RAG是一种AI框架，它将预训练的大语言模型的强大生成能力与外部知识库的实时检索能力相结合。在生成答案之前，RAG系统会首先从一个或多个外部数据源（如数据库、文档库、API等）中检索相关信息，然后将这些信息作为上下文提供给大语言模型，辅助其生成更准确、更相关、基于最新知识的回答。

**工作原理：**
RAG通常包含以下步骤：
1.  **检索 (Retrieval)：** 当用户提出问题或请求时，RAG系统首先使用用户的查询来搜索外部知识库，找出最相关的信息片段。这通常涉及到将知识库中的文档进行向量化处理并存储在向量数据库中，以便进行高效的相似性搜索。
2.  **增强 (Augmentation)：** 检索到的相关信息会与原始的用户提示词一起被整合，形成一个新的、内容更丰富的提示词。
3.  **生成 (Generation)：** 这个增强后的提示词被送入大语言模型，模型基于提供的上下文和其自身的知识来生成最终的回答。

**特点：**
* **获取最新和特定知识：** RAG允许模型访问其预训练数据之外的、可能是实时更新的或私有的知识，从而减少信息过时或"幻觉"（捏造事实）的问题。
* **提高准确性和可信度：** 通过将模型的回答"锚定"在检索到的特定信息上，可以提高输出的准确性和可信度，有时还可以提供信息来源。
* **成本效益：** 相较于对整个模型进行频繁的微调以更新知识，RAG通常更具成本效益，因为它不需要重新训练模型本身，而是通过更新外部知识库来引入新信息。
* **可解释性：** RAG可以提供检索到的信息来源，这为用户理解模型的回答提供了依据。
* **动态知识：** 外部知识库可以独立于大语言模型进行更新和维护。

**用例：**
* 构建能够回答关于特定公司内部文档或最新产品信息的问答系统。
* 为客户服务聊天机器人提供最新的政策信息或故障排除步骤。
* 使模型能够基于最新的研究论文或新闻报道生成摘要或分析。

### 总结与比较

| 特性         | 提示词 (Prompting)                      | 微调 (Fine-tuning)                           | 检索增强生成 (RAG)                                     |
| :----------- | :-------------------------------------- | :------------------------------------------- | :----------------------------------------------------- |
| **核心思想** | 通过输入指导模型                          | 通过额外训练调整模型以适应特定任务               | 在生成前从外部知识库检索信息以增强上下文                   |
| **模型修改** | 不修改模型参数                            | 修改模型参数                                 | 不修改核心模型参数，但依赖外部知识库                     |
| **数据需求** | 无需额外训练数据                          | 需要特定任务的标注数据集                       | 需要可供检索的外部知识库                               |
| **知识来源** | 仅依赖模型的预训练知识                      | 将特定知识内化到模型参数中                       | 结合模型预训练知识和外部实时/特定知识                      |
| **实时性** | 知识基于模型训练截止日期                    | 知识基于微调训练数据的截止日期                   | 可通过更新外部知识库获取相对实时的信息                     |
| **成本** | 低（主要是设计提示词的时间成本）                | 较高（数据收集、标注、计算资源）                 | 中等（知识库构建和维护，检索系统运行成本）                 |
| **适用场景** | 快速实验、通用任务、控制输出风格和格式等        | 对特定领域或任务有高精度要求、需要模型学习特定风格或术语 | 需要利用最新信息、私有数据或减少模型幻觉的场景，提供可溯源的答案 |

**它们之间的关系：**

这三种技术并非相互排斥，而是可以相互补充。
* **提示工程是基础：** 无论是否进行微调或使用RAG，良好的提示词设计对于与大语言模型有效交互都至关重要。
* **RAG 和微调可以结合：** 你可以对一个基础模型进行微调，使其更好地理解特定领域的语言风格和基本概念，然后再结合RAG技术，让其在生成答案时能够利用该领域最新的或更详细的外部知识。
* **选择取决于需求：** 选择哪种技术或组合取决于具体的应用需求、可用资源（数据、算力、时间）以及对模型性能的期望。



# 大模型的基本工作原理
+ 其核心工作原理可以概括为：基于海量数据学习语言模式，并利用这些模式来理解、生成和预测文本。它构建了一个关于语言和世界知识的"概率模型"。
## 预训练 (Pre-training)
+ 这是模型学习语言基础知识的主要阶段。在这个阶段，模型通常会执行一些"无监督学习"任务。最常见的任务之一是语言建模 (Language Modeling)，即预测文本序列中的下一个词。例如，给定句子"今天天气很"，模型需要预测下一个词可能是"好"或"晴朗"。通过在大量文本上进行这种预测练习，模型逐渐学会了语法、语义、常识以及文本中单词之间的统计关系。
## 微调 (Fine-tuning)
+ 在预训练之后，模型可以在更小、更具针对性的数据集上进行微调，以适应特定的任务（如问答、情感分析）或特定的领域（如医学、法律、编程）。
## 生成文本的过程
+ 一旦模型训练完成，它就可以用来生成文本，这个过程称为推理 (Inference)。
当用户提供一个提示 (Prompt) 时，模型会：
* **输入处理 (Input Processing)：** 将提示文本转换为模型可以理解的数字表示（通常是词嵌入embedding）。
* **上下文理解 (Contextual Understanding)：** 通过其内部的 Transformer 层（尤其是自注意力机制、梯度下降）处理这些数字表示，理解提示的含义和上下文。
* **概率分布 (Probability Distribution)：** 在生成下一个词时，模型实际上会输出一个词汇表中所有可能词的概率分布。概率越高的词，模型认为它越适合作为下一个词。
* **词语选择 (Word Selection)：** 有多种策略可以选择下一个词，例如：
    * **贪婪搜索 (Greedy Search)：** 总是选择概率最高的词。这可能导致重复或乏味的文本。
    * **束搜索 (Beam Search)：** 保留几个最可能的候选序列，并在每一步扩展它们，从而找到整体概率较高的序列。
    * **采样 (Sampling)：** 根据概率分布随机选择下一个词，可以引入一定的随机性和创造性。通常会使用像 Temperature 这样的参数来控制随机性的程度（Temperature 越高，随机性越大，输出越有创意但也可能越不连贯）。
* **序列生成 (Sequence Generation)：** 重复步骤3和4，逐词生成文本，直到达到预设的长度、遇到表示结束的特殊标记，或者模型认为已经完成了回答。


# **智能客服场景举例：大模型如何回答客户关于“退货政策”的问题**

假设一家电商公司正在使用一个基于大模型的智能客服系统。

## **1. 预训练阶段的作用**

* **理解语言**： 在海量数据中，大模型学习了关于“退货”、“政策”、“如何”、“可以吗”等词语的含义和它们在句子中的使用方式。
* **理解电商概念**： 它学习了“订单”、“物流”、“商品”、“消费者权益”等电商领域相关的词汇和概念。
* **通用知识**： 模型可能还学习到了关于法律法规、客户服务常识等通用知识，这有助于它理解用户问题的背景。

## **2. 微调（指令微调/RLHF）阶段的作用**

* **遵循指令**： 经过微调，模型能够理解“请帮我查询退货政策”这类指令，而不是仅仅预测下一个词。
* **角色扮演**： 模型被训练成一个“客服助手”的角色，其回复风格更偏向于礼貌、清晰、专业。
* **拒绝不当请求**： 训练模型拒绝回答非法或不相关的问题（例如，用户问“如何制作海洛因”）。
* **结合特定数据**： 如果公司有特定的退货政策文档，这些文档可以作为微调数据的一部分，或者在推理阶段通过检索增强生成（RAG）的方式提供给模型。

## **3. 推理阶段：客户提问“我想退货，请问政策是怎样的？”**

1.  **客户输入 (Prompt)**：
    > “我想退货，请问政策是怎样的？”

2.  **大模型处理**：
    * **理解意图**： 模型通过其在预训练和微调阶段学习到的知识，识别出客户的意图是“查询退货政策”。它会识别关键词“退货”、“政策”。
    * **上下文理解**： 模型可能会识别出这是一个关于“商品退货”的问题，而不是“退款申请”或“换货流程”。
    * **知识检索**： 如果系统集成了检索增强生成（RAG）技术，大模型会触发一个内部流程，去公司的知识库中检索相关的“退货政策”文档或常见问题解答。
    * **生成响应**： 模型结合检索到的具体政策信息，以及它在微调阶段学习到的客服回复风格，生成一个结构化、清晰、友好的回答。如果启用了RAG，模型会优先参考检索到的信息。
        * *比如，如果公司政策是“商品在签收后7天内可无理由退货，需保持商品完好”，模型会把这些信息整合进来。*
        * *如果没有RAG，模型会尝试使用它在预训练阶段“记住”的通用退货知识，但这可能不准确或不够具体。*

3.  **智能客服的回答**：
    > “您好！关于退货政策，我们公司规定：
    > * **无理由退货**： 自您收到商品之日起7天内，如商品不影响二次销售，可以申请无理由退货。
    > * **质量问题**： 如商品存在质量问题，可在签收后15天内申请退换货。
    > * **退货流程**： 请您登录官网，在‘我的订单’中找到对应订单，点击‘申请退货’，按照提示上传图片并填写退货原因。
    > * **运费承担**： 无理由退货产生的运费需由您承担，质量问题退货运费由我们承担。
    >
    > 请问您有具体的订单号或者想退哪件商品呢？我可以帮您进一步查询。”

+ 大模型在智能客服场景中的应用，正是其“**理解语言 -> 检索知识（如果集成） -> 生成有帮助的回复**”这一工作流程的完美体现。预训练赋予了它强大的语言理解能力和通用知识，微调让它变得更擅长遵循指令并扮演特定角色，而最终的推理过程则是将这些能力应用于解决实际的用户问题。



# 大模型的入门资料
+ 大模型原理入门资料
  + https://github.com/rasbt/LLMs-from-scratch/   
+ Transformer架构动画演示
  + https://poloclub.github.io/transformer-explainer/  

# 样例演示
## 使用browser-use AI Agent填写报工的一个简单示例。
